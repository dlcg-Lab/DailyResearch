# 今日CG&DL论文速报

2023-11-07，今日关键词：Rendering，Large Language Model，LLM，NeRF，Real-Time Rendering

今日的计算机图形学和深度学习论文摘要涵盖了图像分割、多模态模型、视觉-语言模型、量子拓扑顺序系统、开放词汇分割评估、语言模型黑盒破解、深度学习映射烧毁区域、六维超重力理论、零视觉外观传递、中子星合并平均场动力、析一个样本学习硬约束马尔科夫随机场、最大似然估计全对应、分布计算机器人依赖因素、有理权重图最短路径、文本分类概念漂移等多元化主题。研究者们通过创新模型和方法提升了科技的发展，也揭示了新的研究方向和未来发展趋势。例如，SegGen的新图像分割训练方法，带来了效率和精确度的提升；FLOGA深度学习模型可映射烧毁区域，对环境保护有重要价值；通过人物调制黑盒破解语言模型也揭示出一些安全隐患。此外，针对量子拓扑顺序系统、六维超重力理论等前沿领域的研究，开辟了全新的理论探索空间。

---
### SegGen: Supercharging Segmentation Models with Text2Mask and Mask2Img Synthesis

**SegGen：利用Text2Mask和Mask2Img合成进行超频段模型分割**：提出了新的图像分割训练方法SegGen

**论文摘要**：

> 我们提出了SegGen，这是一种用于图像分割的高效训练数据生成方法，可以将最先进的分割模型的性能提升到一个显著程度。SegGen设计并集成了两种数据生成策略：MaskSyn和ImgSyn。（1）MaskSyn通过我们提出的文本到蒙版生成模型和蒙版到图片生成模型，生成新的蒙版-图片对，极大地提高了分割蒙版的多样性，提升了模型的监督能力；（2）ImgSyn根据现有的蒙版使用蒙版到图片生成模型，生成新的图片，极大地提高了模型输入的图片多样性。在高度竞争的ADE20K和COCO基准上，我们的数据生成方法显著地提高了最先进的分割模型在语义分割、全景分割和实例分割中的性能。特别是在ADE20K mIoU方面，Mask2Former R50从47.2大幅提高到49.9（+2.7）；Mask2Former Swin-L也从56.1显著增加到57.4（+1.3）。这些有希望的结果强烈地表明，即使在使用了大量人工注释训练数据的情况下，我们的SegGen也非常有效。此外，使用我们的合成数据训练使分割模型对未见领域的抗力更强。项目网站：https://seggenerator.github.io

---

### GLaMM: Pixel Grounding Large Multimodal Model

**GLaMM：像素级大型多模态模型**：展示一种新型的多模式处理模型

**论文摘要**：

> 大型多模态模型（LMMs）将大型语言模型扩展到视觉领域。最初向LMMs的努力使用整体图像和文本提示以产生未接地的文本响应。最近，已经使用了区域级别的LMMs来生成视觉接地响应。然而，它们只限于同时引用一个物体类别，需要用户在输入中指定区域，或无法提供密集像素级的物体接地。在此工作中，我们提出了Grounding LMM (GLaMM)，这是可以生成与相应物体分割掩模紧密交织的自然语言响应的第一个模型。GLaMM不仅接地显示在对话中的对象，而且有足够的灵活性接受文本和可选的视觉提示（关注区域）作为输入。这让用户能够在文本和视觉领域的各种粒度等级上与模型交互。由于缺乏生成视觉接地详细对话的新设定的标准基准，我们引入了一个全面的评估协议，配合我们策划的接地对话。我们提出的接地对话生成 （GCG） 任务需要在大规模自然场景中密集接地概念。为此，我们提出一种密实注释Grounding-anything数据集(Grand) ，使用我们提出的自动化注解流程，涵盖了7.5M独特概念在总共810M区域中得到接地，其都配有分割掩模。除了GCG， GLaMM也在几个下游任务上表现有效，比如，指称表达分割、图像和区域级别字幕和视觉语言对话。项目页面：https://mbzuai-oryx.github.io/groundingLMM.

---

### CoVLM: Composing Visual Entities and Relationships in Large Language Models Via Communicative Decoding

**CoVLM：通过交流解码在大型语言模型中组合视觉实体和关系**：CoVLM改善了大型视觉-语言模型的组合能力

**论文摘要**：

> 人类的一项显著能力在于组合推理，即"有限手段的无限使用"的能力。然而，当前的大型视觉-语言基础模型（VLMs）在组合能力上有所不足，因为它们的"词袋"行为以及无法构造正确代表视觉实体和实体之间关系的词。为此，我们提出了CoVLM，它可以指导LLM明确地组合文本中的视觉实体和关系，并动态地与视觉编码器和检测网络进行通信，实现视觉-语言的交流解码。具体来说，我们首先为LLM设计了一套新的通信令牌，用于视觉检测系统和语言系统之间的动态通信。每个通信令牌都是由LLM在视觉实体或关系之后生成的，以通知检测网络提出与迄今为止生成的句子相关的区域。然后将提出的关注区域（ROIs）反馈给LLM，以便根据相关区域进行更好的语言生成。因此，LLM能够通过通信令牌组合视觉实体和关系。视觉到语言和语言到视觉的通信被反复执行，直到生成整个句子。我们的框架无缝连接了视觉感知和LLM之间的间隙，并在组合推理基准上大幅度优于以前的VLM（例如，HICO-DET mAP上的~20%，Cola top-1准确度上的~14%，和ARO top-1准确度上的~3%）。我们还在传统的视觉-语言任务如指代表达理解和视觉问题回答上取得了最先进的表现。

---

### Topological Orders Having no Topological Quantum Field Theory Description

**没有拓扑量子场论描述的拓扑序**：涉及量子拓扑顺序系统的研究

**论文摘要**：

> 展示量子拓扑序的系统具有坚固的特性，这些特性对于量子计算方案非常吸引人。长久以来，人们一直认为，拓扑有序系统的突出的普遍特征总是被拓扑量子场理论所描述。在当前的工作中，我们说明这并非必然如此。为此，我们构建和研究了一类丰富的二维和三维拓扑有序模型，其中包含相互作用的任意子（阿贝尔和非阿贝尔）。在这些理论中，最低的激发能量取决于任意子的相对几何位置，从而导致不能被拓扑量子场理论所描述的性质。我们通过执行对传统（即，朗道）序的二元性以检查这些模型。我们的方法使得一种把一般的朗道类型理论映射到拓扑有序的对偶模型的通用方法成为可能。我们模型的低能子空间对热效应的抵抗力比表面码的更强。

---

### Rethinking Evaluation Metrics of Open-Vocabulary Segmentaion

**"重新思考开放词汇分割的评估指标"**：“突出开放词汇分割评估问题，提出新指标。”

**论文摘要**：

> 在这篇论文中，我们突出了一个在开放词汇分割中采用的评估指标的问题。那就是，评估过程仍然严重依赖在无射击或跨数据集流水线上的封闭集指标，而没有考虑预测和地面真实类别之间的相似性。为了解决这个问题，我们首先调查了两个分类词之间的十一种相似性测量，使用WordNet语言统计、文本嵌入和语言模型进行了全面的定量分析和用户研究。在这些探索的测量的基础上，我们设计了新的评估指标，即Open mIoU，Open AP和Open PQ，特别适合三种开放词汇分割任务。我们在三个分割任务的12种开放词汇方法上对提出的评估指标进行了基准测试。尽管相似性距离有相对主观性，我们还是证明了我们的指标仍然可以很好地评估现有开放词汇分割方法的开放能力。我们希望我们的工作可以带给社区关于如何评估模型开放能力的新思维。评估代码在github上发布。

---

### Scalable and Transferable Black-Box Jailbreaks for Language Models via Persona Modulation

**通过人物调制实现可扩展和可转移的大语言模型黑盒逃逸**：通过人物调制来黑盒破解大模型，揭示其安全隐患

**论文摘要**：

> 尽管我们已经努力使大型语言模型产生无害的响应，但它们仍然容易受到强制无限制行为的破解提示的影响。在这项工作中，我们通过人物调制作为一种破解方法，引导目标模型扮演那些愿意遵守有害指令的角色。我们不再手动为每个角色构造提示，而是使用语言模型助手自动产生破解。我们展示了由人物调制可能造成的一系列有害结果，包括详细指导如何合成冰毒、制造炸弹和洗钱。\n这种自动攻击在GPT-4中的有害完成率达到42.5%，这是以前调制（0.23%）前的185倍。这些提示也可以转移到Claude2和Vicuna，分别有61.0%和35.9%的有害完成率。我们的工作揭示了商业大型语言模型中的另一个漏洞，并强调了需要更全面的保护措施。

---

### FLOGA: A machine learning ready dataset, a benchmark and a novel deep learning model for burnt area mapping with Sentinel-2

**"FLOGA:利用Sentinel-2进行烧毁区域绘图的机器学习准备数据集，基准和新型深度学习模型"**：新型深度学习模型映射烧毁区域

**论文摘要**：

> 过去的十年里，全球范围的野火频率和强度都在增加，这对人类和动物的生命、生态系统以及社会经济稳定性都构成了重大威胁。因此，需要采取紧急行动，以减轻这些灾害的破坏性影响，保护地球的自然资源。健壮的机器学习方法结合大量的高分辨率卫星图像，可以提供准确和及时的灾区绘制，以此评估事件的规模，识别受影响的资产，有效地优先考虑和分配资源，正确修复受损地区。在这项工作中，我们创造并介绍了一个我们命名为FLOGA（森林火灾观测的希腊地区）的适合机器学习的数据集。这个数据集唯一的地方在于，它包含了野火事件前后获得的卫星图像，包含了Sentinel-2和MODIS模式的信息，这些信息具有不同的空间和光谱分辨率，并且包含了大量的事件，在这些事件中，相关的烧毁区域地面真实已由领域专家注释。FLOGA覆盖了希腊的广大地区，这些地区的特点是地中海的景观和气候条件。我们使用FLOGA来对多种机器学习和深度学习算法进行深入比较，这些算法用于自动提取烧毁区域，这被视为一个变化检测任务。我们还将结果与使用专门的光谱指数进行烧毁区域映射的结果进行了比较。最后，我们提出了一个新的深度学习模型，即BAM-CD。我们的基准测试结果表明，所提出的技术在自动提取烧毁区域方面的效果非常好，在准确度和稳健性方面均优于所有其他方法。我们的数据集和代码可以在以下网址公开获取：https://github.com/Orion-AI-Lab/FLOGA。

---

### New anomaly free supergravities in six dimensions

**'新型无异常超重力理论在六维中的应用**：搜索无异常的六维超重力理论延伸

**论文摘要**：

> 我们使用两种不同的方法进行了对搭配有质量的$N=(1,0)$超重力在六维中无异常的扩展搜寻，我们把这两种方法称为图形和等级方法。在图形方法中，无异常的模型是由被称为节点的单一测量组模型构建的，这些节点只能有重力异常。我们搜索的无异常理论有测量组$G_1\times...\times G_n$（n=1,2,…任意个因数）以及$G_1\times...\times G_n \times U(1)_R$的，其中n=1,2,3，且$U(1)_R$是$R$-对称组。虽然我们主要考虑的模型是张量多元数$n_T=1$，我们也提供了一些$n_T\ne 1$并且带电超多重态数不受限制的结果。我们找到了大量的未测量的无异常理论。然而，在处理带有$n_T=1$的$R$-对称测量模型的情况下，除了已知的带有$G_1\times G_2 \times U(1)_R$类型对称的三种无异常理论之外，我们只找到了六种新型的，表现出人们惊奇的无异常模型，其对称组的形式为$G_1\times G_2\times G_3\times U(1)_R$。在$n_T=1$和未测量模型的情况下，排除了低等级组因素，并只考虑了低位表示，我们找到了所有的无异常理论。引人注意的是，这种类型中的群体因素数量不超过四个。在这种情况下，该完备性的证明依赖于我们为一个参数设立的界限，该参数刻画了非奇点超多重态的数量和测量组维度之间的差异。

---

### Cross-Image Attention for Zero-Shot Appearance Transfer

**跨图像注意力的零次出现传递**：利用文本到图像生成模型进行视觉外观传递

**论文摘要**：

> 近年来，文本到图像的生成模型的进步表现出了对图像深层语义理解的惊人能力。在这项工作中，我们利用这种语义知识来传递那些具有相似语义但形状可能有显著差异的物体之间的视觉外观。为了实现这一点，我们在这些生成模型的自注意力层上进行构建，并引入一个跨图像的注意力机制，该机制隐式地在图像之间建立语义对应。特别地，给定一对图像——一个描绘目标结构，另一个指定期望的外观——我们的跨图像注意力将结构图像对应的查询与外观图像的键和值组合在一起。当在去噪过程中应用这个操作时，它利用已建立的语义对应生成一个结合了期望结构和外观的图像。此外，为了提高输出图像质量，我们利用了三种机制，这些机制要么操作噪声潜码，要么在去噪过程中操作模型的内部表示。重要的是，我们的方法是零次的，不需要优化或训练。实验表明，我们的方法在广泛的对象类别上都有效，对两个输入图像的形状、大小和视点的变化具有鲁棒性。

---

### Impact of a mean field dynamo on neutron star mergers leading to magnetar remnants

**"中子星合并对磁星遗迹的平均场动力学影响"**：探究平均场动力模型对中子星合并后期的影响

**论文摘要**：

> 我们通过推导理想的广义相对论磁流体动力学（GRMHD）方程来研究一个可能在二元中子星合并后期活跃的平均场模型对αΩ-动力机制的影响。这些方程与其牛顿对应物非常相似，但与标准的数值相对论模拟保持兼容。我们为在一个微分旋转的磁星遗迹及其吸积盘的外层的磁旋转不稳定性驱动的湍动动力机制提出了一个启发性的动力闭合关系。作为首次展示，我们将这个框架应用到合并后阶段的早期（≤50 ms）。我们展示出，取决于动力作用的效率，可能会存在带有磁场放大相关质子荷载的磁驱出流。这些出流也可能在稳定进入准稳态之前包含先兆耀发。对于本文研究的动力参数，我们观察到最大的电磁能通量可达10^50 erg/s，尽管更大的放大参数可能导致更强的通量。我们的结果与预期保持一致，即在合并期间或之后可能需要显著的动力放大，以使中子星遗迹能够为短伽马射线爆或其先兆供能。

---

### Learning Hard-Constrained Models with One Sample

**"用一个样本学习硬约束模型"**：考虑用一个样本学习硬约束马尔科夫随机场

**论文摘要**：

> 本文考虑了用单个样本估计具有硬约束的马尔科夫随机场的参数问题。作为我们主要的运行示例，我们使用了$k$-SAT和正确的颜色模型，以及一般的$H$-颜色模型；对所有这些，我们都得到了积极和消极的结果。与软约束情况相比，我们特别显示，单样本估算并非总是可能的，且估算器的存在与不满足实例的存在有关。我们的算法是基于伪似然估计器的。我们展示了这个估计器的方差边界，使用由Moitra的采样算法（JACM，2019）在$k$-SAT案例中启发的耦合技术；我们的颜色构建正面结果建立在这种新的耦合方法上。对于具有最大度数$d$的图的$q$-彩色，当$q>d+1$时，我们提供了一个线性时间估计器，而当$q\leq d+1$时，问题不可识别。对于一般的$H$-颜色，我们显示，保证采样的标准条件，如Dobrushin的条件，对于一个样本的学习是不够的；在积极的一面，我们提供了一个足够保证线性时间学习的一般条件，并得到对于正确的颜色和允许的模型的应用。对于在公式上具有最大度数$d$的$k$-SAT模型，当$k\gtrsim 6.45\log d$时，我们提供了一个线性时间估计器，而当$k\lesssim \log d$时，问题变得不可识别。

---

### Complete collineations for maximum likelihood estimation

**'最大似然估计的完全对应**：介绍最大似然估计中完全对应的新方法概念

**论文摘要**：

> 我们引入了代数几何概念的完全对应到最大可能性估计的研究中，在有向高斯图形模型中。一个完整的对应产生了样本数据的扰动，我们把它称为样本的稳定化。虽然在给定样本数据的情况下，最大似然估计（MLE）可能不存在或者不是唯一的，但是在给定稳定化的情况下，它总是唯一的。我们关联了给定稳定化的MLE和给定原始样本数据的MLE（如果存在的话），提供了给定稳定化的MLE是给定原始样本的必要和充分条件。对于线性回归模型，我们证明了给任何稳定化的MLE是在给定一个原始样本的MLEs中的最小范数选择。我们表明MLE在样板稳定化倾向于原始样本时有一个明确定义的极限，而这个极限是给原始样本的一个MLE，当它存在时。最后，我们研究哪些给样本的MLEs可以作为这样的极限出现。我们将这个问题简化为关于某些代数品种的非空性的问题。'

---

### On Asynchrony, Memory, and Communication: Separations and Landscapes

**关于异步、内存和通信：分离与景观**：研究分布式计算中的机器人计算能力依赖因素

**论文摘要**：

> 研究团队对称性移动计算实体（即机器人）在欧氏空间中通过查看-计算-移动(LCM)周期进行分布式计算的研究，近来主要集中在更好地理解机器人的计算能力如何依赖于他们的内部能力（即，持久的记忆，通信）与外部环境条件之间的交互，后者通过控制机器人的激活和他们的活动同步（被感知和建模为对抗调度程序）来捕获。我们考虑一组对抗性的异步调度程序，从经典的半同步 (SSYNCH) 和全异步 (ASYNCH) 设置，包括调度程序（在研究LCM周期中操作组合的原子性时出现）其对抗力量在这两者之间。我们提问：模型 M1 下的对抗调度器 K1 (M1(K1))与模型 M2 下的调度器 K2 (M2(K2))之间的计算关系是什么？例如，M1(K1)中的机器人是否比M2(K2)中的机器人更有能力（即，他们可以解决更多的问题）？
我们通过跨模型分析回答所有这些问题，提供了对在考虑的异步调度器下这四种机器人模型的功率之间计算关系的完整表述。在这个过程中，我们也提供了对几个开放问题的合格答案，包括在无限可见性的情况下，通行的优势对ASY的适当主导力的杰出问题。

---

### Exact Shortest Paths with Rational Weights on the Word RAM

**在Word RAM上计算有理权重的精确最短路径**：在Word RAM上研究有理权重图的最短路径

**论文摘要**：

> 在传统上，对权重图中最短路径的精确计算一直在两种设置中研究。首先，人们可以假设边权重是实数，对实数进行的所有操作（通常是比较和加法）都需要恒定的时间。在这个设置中描述了经典的Dijkstra和Bellman-Ford算法。对于整数权重图，已经得到了更有效的精确最短路径算法。整数假设不仅使算法运行速度更快，而且还允许在更实际的Word RAM模型中实现上述算法，在该模型中，只有对$O(\log{n})$位整数执行的算术操作才能在恒定时间内完成。在Word RAM上，人们甚至可以以同样高效的方式精确编码具有$O(\log{n})$位分子和分母的rational-weighted实例。然而，已知的精确的实数权重最短路径算法在此类有理输入上运行时，可能会很容易地遇到精确表示的$\Theta(n)$位的中间值。这导致在Word RAM上的$\Omega(n)$的减速。与此同时，适合整数权重的缩放算法对有理输入无法产生精确解，除非显著提高其准确度。在本文中，我们设计了在Word RAM上对有理权重图进行随机精确单源最短路径算法。最重要的是，在非负情况下，我们获得了一种近似线性时间算法，其运行时间与Dijkstra的算法相匹配，直到多对数因子。在存在负权重的情况下，我们提供了一个$\tilde{O}(n^{2.5})$时间算法，破了Bellman-Ford算法对于足够密集图的最好的已知强多项式界。

---

### Tackling Concept Shift in Text Classification using Entailment-style Modeling

**"使用蕴涵式建模来解决文本分类中的概念漂移"**：利用蕴涵式建模解决文本分类概念漂移

**论文摘要**：

> 预训练语言模型（PLMs）在自然语言处理（NLP）中的文本分类（TC）问题上取得了巨大成功。在许多实际的文本分类任务中，所学习的类定义并不是恒定的，而是会随着时间的推移发生变化——这被称为概念漂移。大多数处理概念漂移的技术都依赖于用新标记的数据重新训练旧的分类器。然而，给定用于微调新概念的大型DL模型所需的训练数据量，相关的标记成本可能会过于昂贵并且耗时。在这项工作中，我们提出了一种重新定义，将普通的分类转变为一个蕴涵式问题，这需要大大减少重新训练文本分类器以适应新概念的数据量。我们在真实世界和合成数据集上都展示了我们提出的方法的有效性，分别在少数设置下获得了最高7%和40%的F1得分增益。此外，在部署后，我们的解决方案还帮助节省了75%的标记成本。

---

### DAIL: Data Augmentation for In-Context Learning via Self-Paraphrase

**DAIL：自我释义的情境学习数据增强技术**：DAIL技术提高了情境学习的表现。

**论文摘要**：

> 情境学习（ICL）结合了预训练的大型语言模型，已经在各种NLP任务上取得了令人鼓舞的结果。然而，ICL需要高质量的注释示例，这在现实世界的情境中可能无法获得。为了克服这个限制，我们提出了一种用于情境学习的数据增强技术（DAIL）。DAIL利用了大型语言模型更熟悉由它们自身生成的内容的直觉。它首先使用语言模型生成测试样本的释义，然后利用多数投票的方式确定基于个体预测的最终结果。我们的大量经验性评估显示，DAIL在低资源情境中比标准的ICL方法和其他基于集成的方法表现得更好。此外，我们还探讨了在无法访问预测的logits时，使用投票一致性作为模型的信心分数。我们相信我们的工作将刺激对低资源设置中ICL的进一步研究。

---

